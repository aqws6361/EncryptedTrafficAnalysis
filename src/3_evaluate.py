import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
import os
import platform

# --- è‡ªå‹•è¨­å®šä¸­æ–‡å­—é«” (è§£æ±º Matplotlib ä¸­æ–‡äº‚ç¢¼å•é¡Œ) ---
def set_chinese_font():
    system_name = platform.system()
    if system_name == "Windows":
        # Windows ä½¿ç”¨å¾®è»Ÿæ­£é»‘é«”
        plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei']
    elif system_name == "Darwin":
        # Mac ä½¿ç”¨é»‘é«”
        plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']
    else:
        # Linux (Colab/Ubuntu) å˜—è©¦å¸¸è¦‹ä¸­æ–‡å­—é«”
        plt.rcParams['font.sans-serif'] = ['WenQuanYi Zen Hei', 'Droid Sans Fallback']
    
    # è§£æ±ºè² è™Ÿ '-' é¡¯ç¤ºç‚ºæ–¹å¡Šçš„å•é¡Œ
    plt.rcParams['axes.unicode_minus'] = False

# å‘¼å«è¨­å®šå‡½å¼
set_chinese_font()

# --- 1. å®šç¾©æ¨¡å‹ (éœ€èˆ‡è¨“ç·´æ™‚ä¸€è‡´) ---
class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=5000):
        super(PositionalEncoding, self).__init__()
        # Compute the positional encodings once in log space.
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len).unsqueeze(1).float()
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(np.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0)
        self.register_buffer('pe', pe)

    def forward(self, x):
        return x + self.pe[:, :x.size(1)]

class MalwareDetectorTransformer(nn.Module):
    def __init__(self, input_size, d_model, num_classes, nhead=4, num_layers=2, dim_feedforward=128, dropout=0.1):
        super(MalwareDetectorTransformer, self).__init__()
        
        # 1. Feature Embedding: Project 2D features to d_model
        self.embedding = nn.Linear(input_size, d_model)
        self.pos_encoder = PositionalEncoding(d_model)
        
        # 2. Transformer Encoder
        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, batch_first=True)
        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)
        
        # 3. Classifier
        self.fc = nn.Linear(d_model, num_classes)
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x):
        # x shape: (batch_size, seq_len, input_size)
        x = self.embedding(x)  # -> (batch, seq_len, d_model)
        x = self.pos_encoder(x)
        x = self.transformer_encoder(x)
        
        # Global Average Pooling
        x = x.mean(dim=1)  # -> (batch, d_model)
        x = self.dropout(x)
        out = self.fc(x)
        return out

def evaluate_performance():
    # --- é—œéµä¿®æ­£ï¼šè‡ªå‹•å®šä½è·¯å¾‘ ---
    # 1. å–å¾—ç›®å‰é€™æ”¯ç¨‹å¼ (3_evaluate.py) æ‰€åœ¨çš„è³‡æ–™å¤¾è·¯å¾‘ (ä¾‹å¦‚ .../src)
    current_dir = os.path.dirname(os.path.abspath(__file__))
    
    # 2. å–å¾—å°ˆæ¡ˆæ ¹ç›®éŒ„ (src çš„ä¸Šä¸€å±¤)
    project_root = os.path.dirname(current_dir)
    
    # 3. çµ„åˆå‡ºæ­£ç¢ºçš„æª”æ¡ˆè·¯å¾‘
    x_path = os.path.join(project_root, "data", "X_data.npy")
    y_path = os.path.join(project_root, "data", "y_data.npy")
    model_path = os.path.join(project_root, "model", "iot_malware_model.pth") 
    
    # åœ–ç‰‡å­˜æª”è·¯å¾‘
    cm_plot_path = os.path.join(project_root, 'confusion_matrix.png')

    print(f"DEBUG: é æœŸè³‡æ–™è·¯å¾‘: {x_path}")
    print(f"DEBUG: é æœŸæ¨¡å‹è·¯å¾‘: {model_path}")

    # è¨­å®šåƒæ•¸
    INPUT_SIZE = 2
    D_MODEL = 64
    NUM_CLASSES = 2
    
    # æª¢æŸ¥æª”æ¡ˆ
    if not os.path.exists(x_path) or not os.path.exists(y_path):
        print(f"âŒ æ‰¾ä¸åˆ°æ•¸æ“šæª”æ¡ˆï¼Œè«‹ç¢ºèªæª”æ¡ˆæ˜¯å¦åœ¨ {x_path}")
        return

    if not os.path.exists(model_path):
        print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆï¼Œè«‹ç¢ºèªæª”æ¡ˆæ˜¯å¦åœ¨ {model_path}")
        return

    # --- 2. è¼‰å…¥è³‡æ–™ ---
    print("æ­£åœ¨è¼‰å…¥æ¸¬è©¦æ•¸æ“š...")
    X = np.load(x_path)
    y = np.load(y_path)
    
    # åˆ‡åˆ†æ¸¬è©¦é›† (è·Ÿè¨“ç·´æ™‚ä¸€æ¨£ Random State æ‰èƒ½ç¢ºä¿æ˜¯åŒä¸€ä»½æ¸¬è©¦é›†)
    _, X_test, _, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # è½‰ Tensor
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    X_test_tensor = torch.from_numpy(X_test).to(device)
    y_test_tensor = torch.from_numpy(y_test).long().to(device)

    # --- 3. è¼‰å…¥æ¨¡å‹ ---
    print(f"æ­£åœ¨è¼‰å…¥æ¨¡å‹...")
    model = MalwareDetectorTransformer(INPUT_SIZE, D_MODEL, NUM_CLASSES).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()

    # --- 4. é€²è¡Œé æ¸¬ ---
    print("æ­£åœ¨é€²è¡Œæ¨è«–...")
    with torch.no_grad():
        outputs = model(X_test_tensor)
        _, predicted = torch.max(outputs.data, 1)
    
    # è½‰å› CPU Numpy
    y_true = y_test_tensor.cpu().numpy()
    y_pred = predicted.cpu().numpy()

    # --- 5. ç”¢ç”Ÿå ±è¡¨ ---
    print("\n" + "="*40)
    print("ğŸ“Š åˆ†é¡è©³ç´°å ±è¡¨ (Classification Report)")
    print("="*40)
    
    target_names = ['Benign (è‰¯æ€§)', 'Attack (æƒ¡æ„)']
    report = classification_report(y_true, y_pred, target_names=target_names)
    print(report)

    # --- 6. ç¹ªè£½æ··æ·†çŸ©é™£ ---
    print("æ­£åœ¨ç¹ªè£½æ··æ·†çŸ©é™£...")
    cm = confusion_matrix(y_true, y_pred)
    
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=target_names, 
                yticklabels=target_names)
    plt.xlabel('Predicted Label (é æ¸¬)')
    plt.ylabel('True Label (çœŸå¯¦)')
    plt.title('Confusion Matrix - IoT Malware Detection')
    
    # å­˜æª”
    plt.savefig(cm_plot_path)
    print(f"âœ… æ··æ·†çŸ©é™£å·²å„²å­˜ç‚º: {cm_plot_path}")
    # é—œé–‰åœ–è¡¨ä»¥é‡‹æ”¾è¨˜æ†¶é«”ï¼Œé¿å…åœ¨ç„¡é¡¯ç¤ºç’°å¢ƒå‡ºéŒ¯
    plt.close()

if __name__ == "__main__":
    evaluate_performance()